# ğŸ  Scraper de ImÃ³veis da Caixa v1.1

[![Python Version](https://img.shields.io/badge/python-3.10%2B-blue)](https://www.python.org/downloads/)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

> Scraper automatizado e profissional para buscar imÃ³veis em leilÃ£o da Caixa EconÃ´mica Federal.

---

## ğŸ“‹ Ãndice

- [Sobre](#sobre)
- [Novidades v1.1](#novidades-v11)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso BÃ¡sico](#uso-bÃ¡sico)
- [Arquitetura](#arquitetura)
- [Desenvolvimento](#desenvolvimento)
- [Contribuindo](#contribuindo)
- [LicenÃ§a](#licenÃ§a)

---

## ğŸ¯ Sobre

Este projeto realiza scraping automatizado de imÃ³veis em leilÃ£o da **Caixa EconÃ´mica Federal**, extraindo informaÃ§Ãµes como:

- ğŸ˜ï¸ Nome do imÃ³vel
- ğŸ“ EndereÃ§o completo
- ğŸ’° Valor de avaliaÃ§Ã£o
- ğŸ›ï¸ NÃºmero de quartos
- ğŸ”— Link direto para o imÃ³vel

### Principais Recursos

âœ… **AutomatizaÃ§Ã£o completa** com Selenium  
âœ… **Multi-cidades** - busca em vÃ¡rias cidades simultaneamente  
âœ… **Anti-detecÃ§Ã£o** - configurado para evitar bloqueios  
âœ… **RelatÃ³rios** - gera CSV, JSON e relatÃ³rios de texto  
âœ… **Screenshots** - captura tela de cada busca  
âœ… **Logging profissional** - rastreabilidade completa  
âœ… **Type-safe** - type hints em todo o cÃ³digo  
âœ… **TestÃ¡vel** - arquitetura modular preparada para testes  

---

## âœ¨ Novidades v1.1

### ğŸ—ï¸ **RefatoraÃ§Ã£o Completa**

A versÃ£o 1.1 traz uma refatoraÃ§Ã£o profunda seguindo **boas prÃ¡ticas de cÃ³digo**:

#### Arquitetura Modular
```
src/scraper_caixa/
â”œâ”€â”€ config.py         # ConfiguraÃ§Ãµes centralizadas
â”œâ”€â”€ driver.py         # Gerenciamento do ChromeDriver
â”œâ”€â”€ exceptions.py     # ExceÃ§Ãµes personalizadas
â”œâ”€â”€ logger.py         # Sistema de logging
â”œâ”€â”€ types.py          # Type hints e definiÃ§Ãµes
â””â”€â”€ scraper.py        # LÃ³gica principal
```

#### Melhorias TÃ©cnicas
- âœ… **PEP 8** - cÃ³digo formatado com Black
- âœ… **Type Hints** - tipagem completa
- âœ… **Logging** - substituiÃ§Ã£o de prints
- âœ… **Docstrings** - documentaÃ§Ã£o PEP 257
- âœ… **ConfiguraÃ§Ã£o** - separada de cÃ³digo
- âœ… **ExceÃ§Ãµes** - hierarquia especÃ­fica

#### ConfiguraÃ§Ã£o Moderna
- âœ… `pyproject.toml` - configuraÃ§Ã£o centralizada
- âœ… DependÃªncias fixas - reprodutibilidade
- âœ… Dev tools - black, mypy, pytest

Veja detalhes em [CHANGELOG.md](CHANGELOG.md) e [REFATORACAO_V1.1.md](REFATORACAO_V1.1.md).

---

## ğŸ“¦ InstalaÃ§Ã£o

### Requisitos
- Python 3.10 ou superior
- Google Chrome instalado
- pip

### InstalaÃ§Ã£o BÃ¡sica

```bash
# Clonar repositÃ³rio
git clone https://github.com/RafaAmft/Scraper-leilao-caixa.git
cd Scraper-leilao-caixa

# Instalar dependÃªncias
pip install -r requirements.txt

# Ou instalar em modo desenvolvimento
pip install -e ".[dev]"
```

### Verificar InstalaÃ§Ã£o

```bash
python -c "from scraper_caixa import __version__; print(__version__)"
# Deve exibir: 1.1.0
```

---

## ğŸš€ Uso BÃ¡sico

### Exemplo Simples

```python
from scraper_caixa import (
    configurar_chromedriver,
    ScraperConfig,
    get_logger,
    FiltrosBusca,
)

# Configurar logger
logger = get_logger(__name__)

# Configurar scraper
config = ScraperConfig(
    headless=True,
    save_screenshots=True,
    save_json=True,
)

# Configurar driver
driver = configurar_chromedriver(config)

# Definir filtros de busca
filtros: FiltrosBusca = {
    "estado": "SC",
    "codigo_cidade": "8690",
    "nome_cidade": "JOINVILLE",
    "tipo_imovel": "4",  # Indiferente
}

# Executar busca
# (implementaÃ§Ã£o do scraper em desenvolvimento)

# Fechar driver
driver.quit()
```

### ConfiguraÃ§Ã£o Personalizada

```python
from scraper_caixa.config import ScraperConfig
from pathlib import Path

config = ScraperConfig(
    headless=False,           # Ver navegador
    timeout=60,               # Timeout maior
    max_retries=5,            # Mais tentativas
    save_screenshots=True,
    data_dir=Path("./meus_dados"),
)
```

---

## ğŸ—ï¸ Arquitetura

### MÃ³dulos Principais

#### 1. `config.py` - ConfiguraÃ§Ãµes
```python
from scraper_caixa.config import (
    URL_BASE,
    CHROME_OPTIONS,
    ESTADOS_CIDADES,
    ScraperConfig,
)
```

#### 2. `driver.py` - ChromeDriver
```python
from scraper_caixa.driver import configurar_chromedriver

driver = configurar_chromedriver()
```

#### 3. `logger.py` - Logging
```python
from scraper_caixa.logger import get_logger

logger = get_logger(__name__)
logger.info("Mensagem de log")
```

#### 4. `exceptions.py` - ExceÃ§Ãµes
```python
from scraper_caixa.exceptions import (
    ScraperError,
    ChromeDriverError,
    NavigationError,
)

try:
    # cÃ³digo
    pass
except ChromeDriverError as e:
    logger.error(f"Erro: {e}")
```

#### 5. `types.py` - Type Hints
```python
from scraper_caixa.types import FiltrosBusca, DadosImovel

filtros: FiltrosBusca = {
    "estado": "SC",
    "codigo_cidade": "8690",
}
```

---

## ğŸ› ï¸ Desenvolvimento

### Setup Ambiente de Desenvolvimento

```bash
# Instalar dependÃªncias de desenvolvimento
pip install -r requirements-dev.txt

# Instalar pre-commit hooks (recomendado)
pre-commit install
```

### Ferramentas de Qualidade

#### FormataÃ§Ã£o de CÃ³digo
```bash
# Formatar com Black
black src/ tests/

# Ordenar imports com isort
isort src/ tests/
```

#### VerificaÃ§Ã£o de Estilo
```bash
# Verificar com flake8
flake8 src/ tests/

# Verificar tipos com mypy
mypy src/
```

#### Testes
```bash
# Executar testes (quando implementados)
pytest

# Com cobertura
pytest --cov=src --cov-report=html
```

### Estrutura de DiretÃ³rios

```
projeto/
â”œâ”€â”€ src/scraper_caixa/        # CÃ³digo fonte
â”œâ”€â”€ tests/                     # Testes unitÃ¡rios
â”œâ”€â”€ docs/                      # DocumentaÃ§Ã£o
â”œâ”€â”€ dados_imoveis/             # Dados extraÃ­dos
â”œâ”€â”€ screenshots/               # Capturas de tela
â”œâ”€â”€ relatorios/                # RelatÃ³rios gerados
â”œâ”€â”€ logs/                      # Arquivos de log
â”œâ”€â”€ pyproject.toml             # ConfiguraÃ§Ã£o do projeto
â”œâ”€â”€ requirements.txt           # DependÃªncias produÃ§Ã£o
â””â”€â”€ requirements-dev.txt       # DependÃªncias desenvolvimento
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- ğŸ“˜ [Boas PrÃ¡ticas](boaspraticas.md) - Guia de boas prÃ¡ticas
- ğŸ“ [Changelog](CHANGELOG.md) - HistÃ³rico de mudanÃ§as
- ğŸ”§ [RefatoraÃ§Ã£o v1.1](REFATORACAO_V1.1.md) - Detalhes da refatoraÃ§Ã£o
- ğŸ“Š [Resumo](RESUMO_REFATORACAO.md) - Resumo executivo

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'feat: Adicionar feature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

### PadrÃµes

- Seguir [PEP 8](https://peps.python.org/pep-0008/)
- Usar [Conventional Commits](https://www.conventionalcommits.org/)
- Adicionar testes para novas features
- Atualizar documentaÃ§Ã£o

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja [LICENSE](LICENSE) para mais detalhes.

---

## ğŸ‘¤ Autor

**Rafael Fontes**
- Email: rafael.a.fontes@hotmail.com
- GitHub: [@RafaAmft](https://github.com/RafaAmft)

---

## ğŸ™ Agradecimentos

- Comunidade Python
- Selenium WebDriver
- Todos os contribuidores

---

## ğŸ“ Suporte

Encontrou um bug? Tem uma sugestÃ£o?

- ğŸ› [Abra uma issue](https://github.com/RafaAmft/Scraper-leilao-caixa/issues)
- ğŸ’¬ [Inicie uma discussÃ£o](https://github.com/RafaAmft/Scraper-leilao-caixa/discussions)

---

**â­ Se este projeto te ajudou, considere dar uma estrela!**

---

Feito com â¤ï¸ e â˜• por Rafael Fontes

